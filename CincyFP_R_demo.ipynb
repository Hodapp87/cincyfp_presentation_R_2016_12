{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "notes"
    }
   },
   "source": [
    "# Rough Outline\n",
    "\n",
    "## Core\n",
    "- Vectors, Boolean vectors, indexing\n",
    "- Matrices & indexing\n",
    "- Negative indices\n",
    "- Defining functions\n",
    "  - Function composition\n",
    "  - Function scoping\n",
    "  - Pass-by-value\n",
    "- Dataframes (mtcars)\n",
    "- Missing values\n",
    "- Factors\n",
    "\n",
    "## Data transformation\n",
    "- Wide-format vs. long-format\n",
    "\n",
    "## Visualization\n",
    "\n",
    "## reshape2, dplyr\n",
    "\n",
    "## Misc\n",
    "- `help(...)` or `? ...`\n",
    "- Tab-completion in Jupyter\n",
    "- SparkR (if possible)\n",
    "\n",
    "## To-do\n",
    "- dpylr examples\n",
    "- ggplot2 examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Brief Introduction to R & Feature Transformation\n",
    "## Chris Hodapp <hodapp87@gmail.com>\n",
    "\n",
    "## CincyFP, 2016 December 13"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Front matter\n",
    "\n",
    "This is all done in Jupyter (formerly IPython) and IRkernel.\n",
    "- https://jupyter.org/\n",
    "- https://irkernel.github.io/\n",
    "\n",
    "Visit http://... to use this same notebook in your browser.\n",
    "\n",
    "(...unless you're reading this later, of course.  Go fire up your own docker container with `\"docker run -d -p 8888:8888 jupyter/r-notebook\"` or something.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "![](r-matey2.png)\n",
    "\n",
    "(thanks Creighton)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What is R?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- An interpreted, dynamically-typed language based on S and made mainly for interactive use in statistics and visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Sort of like MATLAB, except statistics-flavored and open source"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- A train-wreck that is sometimes confused with a real programming language.\n",
    "  - *\"R is a dynamic language for statistical computing that combines lazy functional features and object-oriented programming. This rather unlikely linguistic cocktail would probably never have been prepared by computer scientists, yet the language has become surprisingly popular.\"*\n",
    "  - The R Inferno (Patrick Burns), http://www.burns-stat.com/pages/Tutor/R_inferno.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## So... why use it at all?\n",
    "\n",
    "- Stable and documented extensively!\n",
    "- Excellent for exploratory use interactively!\n",
    "- Epic visualization!\n",
    "- Magical, fast, and elegant for arrays, tables, vectors, and linear algebra!\n",
    "- Huge standard library!\n",
    "- Packages for everything else on CRAN!\n",
    "- Still sort of FP!\n",
    "- Excellent tooling! (Sweave, Emacs & ESS mode, RStudio, Jupyter...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## How do I use R?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*Do you need plotting or visualization?*\n",
    "Use [ggplot2](http://ggplot2.org/). Completely ignore built-in plotting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*Do you need to transform tabular/vector/list/array/matrix/DataFrame data somehow?*\n",
    "Just use [dpylr](https://cran.r-project.org/package=dplyr) or [reshape2](http://seananderson.ca/2013/10/19/reshape.html). Completely ignore built in `*apply` functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*Do you need something else?* Search [CRAN](https://cran.r-project.org/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*Does no CRAN package solve your problems? Do you need to write \"real\"(tm) software for production?* Strongly consider giving up."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Obligatory R notebook demonstration..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dplyr\n",
    "\n",
    "- See: Introduction to dplyr, https://cran.rstudio.com/web/packages/dplyr/vignettes/introduction.html\n",
    "- `filter`, `slice` - Select rows (filter is by predicate, slice is by position)\n",
    "- `arrange` - Reorder rows\n",
    "- `select`, `rename` - Select columns\n",
    "- `distinct` - Choose only *distinct* rows\n",
    "- `mutate`, `transmute` - Make new columns from existing ones\n",
    "- `summarise` - Collapse frame to single row with aggregate functions\n",
    "- `sample_n`, `sample_frac` - Randomly sample (by count or by percentage)\n",
    "- `group_by` - Group observations (most of above worked on grouped observations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Motivating Example\n",
    "\n",
    "- Example data set from: https://archive.ics.uci.edu/ml/datasets/Letter+Recognition\n",
    "- 20,000 samples, 16 dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# I'm not going to remember this code\n",
    "letters <- read.table(\"letter-recognition.data\", sep=\",\", header=FALSE);\n",
    "colnames(letters) <- c(\"Letter\", \"Xbox\", \"Ybox\", \"Width\", \"Height\",\n",
    "                       \"OnPix\", \"Xbar\", \"Ybar\", \"X2bar\", \"Y2bar\",\n",
    "                       \"XYbar\", \"X2Ybar\", \"XY2bar\", \"Xedge\",\n",
    "                       \"XedgeXY\", \"Yedge\", \"YedgeYX\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## *Curse of Dimensionality* (Bellman)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/c/cc/Data3classes.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "![](https://upload.wikimedia.org/wikipedia/commons/5/52/Map1NN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Intuition from k-nearest neighbor: If each sample occupies a certain amount of 'space' in the input space, the number of samples required to still 'cover' that space increases exponentially with the number of dimensions.\n",
    "- If possible: Don't add more dimensions. Either reduce dimensions, or increase samples."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Feature Transformation\n",
    "\n",
    "### General form\n",
    "\n",
    "$$x : \\mathcal{F}^N \\mapsto \\mathcal{F}^M, M < N$$\n",
    "\n",
    "*(though actually `M >> N` is useful too and is the basis for [kernel methods](https://en.wikipedia.or/wiki/Kernel_method) such as SVMs)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Subsets\n",
    "- *Feature Selection*: Loosely, throw away dimensions/features.\n",
    "- Information gain, Gini index, entropy, variance, statistical independence..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- *Filtering*: Reduce features first, and then perform learning. Learning can't feed information 'back' to filtering."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- *Wrapping*: Reduce features based on how learning performs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Subsets\n",
    "\n",
    "#### Linear\n",
    "\n",
    "- Transformation $x : \\mathcal{F}^N \\mapsto \\mathcal{F}^M, M < N$ is defined by $N\\times M \\textrm{ matrix }\\mathcal{P}_x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- e.g. 4-dimensional feature space mapped to 2 dimensions, $(x_1, x_2, x_3, x_4) \\mapsto (2x_1-x_2, x_3 + x_4)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then for samples as column vectors...\n",
    "$$\n",
    "\\mathcal{P}_x=\n",
    "  \\begin{bmatrix}\n",
    "    2 & -1 & 0 & 0 \\\\\n",
    "    0 & 0 & 1 & 1\n",
    "  \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Consider data expressed as an $n\\times m$ matrix with each column representing one *feature* (of $m$) and each row one *sample* (of $n$):\n",
    "\n",
    "$$\n",
    "X=\n",
    "  \\begin{bmatrix}\n",
    "    a_1 & b_1 & c_1 & \\cdots\\\\\n",
    "    a_2 & b_2 & c_2 & \\cdots\\\\\n",
    "    a_3 & b_3 & c_3 & \\cdots\\\\\n",
    "    \\cdots & \\cdots & \\cdots & \\cdots\\\\\n",
    "    a_n & b_n & c_n & \\cdots\\\\\n",
    "  \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Focus on first feature $A=\\left\\{a_1, a_2, \\dots\\right\\}$\n",
    "- Mean = $\\left\\langle a_i \\right\\rangle_i = \\frac{1}{n} \\sum_i^n a_i=\\mu_A$\n",
    "  - $\\left\\langle \\dots \\right\\rangle$ = expectation operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Variance:\n",
    "$$\\sigma_A^2=\\left\\langle \\left(a_i-\\left\\langle a_j \\right\\rangle _j\\right)^2 \\right\\rangle_i=\\left\\langle \\left(a_i-\\mu_A\\right)^2 \\right\\rangle_i = \\frac{1}{n-1}\\sum_i^n \\left(a_i-\\mu_A\\right)^2$$\n",
    "\n",
    "*(if you want to know why it is $\\frac{1}{n-1}$ and not $\\frac{1}{n}$, ask a statistics PhD or something)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Consider another sample $B=\\left\\{b_1, b_2, \\dots\\right\\}$, and assume that $\\mu_A=\\mu_B=0$ for sanity\n",
    "- Covariance of $A$ and $B$:\n",
    "$$\\sigma_{AB}^2=\\left\\langle a_i b_i \\right\\rangle_i=\\frac{1}{n-1}\\sum_i^n a_i b_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Treating $A$ and $B$ as vectors:\n",
    "\n",
    "$$\\sigma_{AB}^2=\\frac{A\\cdot B}{n-1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Recalling our data matrix:\n",
    "\n",
    "$$\n",
    "X=\n",
    "  \\begin{bmatrix}\n",
    "    a_1 & b_1 & c_1 & \\cdots\\\\\n",
    "    a_2 & b_2 & c_2 & \\cdots\\\\\n",
    "    a_3 & b_3 & c_3 & \\cdots\\\\\n",
    "    \\cdots & \\cdots & \\cdots & \\cdots\\\\\n",
    "    a_n & b_n & c_n & \\cdots\\\\\n",
    "  \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "It can be rewritten as column vectors:\n",
    "\n",
    "$$\n",
    "X=\n",
    "  \\begin{bmatrix}\n",
    "    a_1 & b_1 & c_1 & \\cdots\\\\\n",
    "    a_2 & b_2 & c_2 & \\cdots\\\\\n",
    "    a_3 & b_3 & c_3 & \\cdots\\\\\n",
    "    \\cdots & \\cdots & \\cdots & \\cdots\\\\\n",
    "    a_n & b_n & c_n & \\cdots\\\\\n",
    "  \\end{bmatrix}\n",
    "  =\\begin{bmatrix}\n",
    "  A & B & C & \\cdots\n",
    "  \\end{bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Then *covariance matrix* is:\n",
    "\n",
    "$$\\mathbf{S}_X=\\frac{X^\\top X}{n-1}=\n",
    "  \\begin{bmatrix}\n",
    "    \\sigma_{A}^2 & \\sigma_{AB}^2 & \\sigma_{AC}^2 & \\sigma_{AD}^2 & \\cdots \\\\\n",
    "    \\sigma_{AB}^2 & \\sigma_{B}^2 & \\sigma_{BC}^2 & \\sigma_{BD}^2 & \\cdots \\\\\n",
    "    \\sigma_{AC}^2 & \\sigma_{BC}^2 & \\sigma_{C}^2 & \\sigma_{CD}^2 & \\cdots \\\\\n",
    "    \\sigma_{AD}^2 & \\sigma_{BD}^2 & \\sigma_{CD}^2 & \\sigma_{D}^2 & \\cdots \\\\\n",
    "    \\cdots & \\cdots & \\cdots & \\cdots\n",
    "  \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "- Square ($m \\times m$), symmetric, variances on diagonals, covariances off diagonals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "- If all features are completely independent of each other, then all covariances are 0.\n",
    "- That is: The covariance matrix is a *diagonal matrix* (all zeros, except for its diagonals).\n",
    "- So... What is this matrix $P$ such that for $Y=XP$, covariance matrix $\\mathbf{S}_Y$ is diagonal?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- Like basically every other question in linear algebra, the answers are:\n",
    "  - Eigendecomposition\n",
    "  - SVD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- That magical transform matrix $P$ equals a matrix whose columns are eigenvectors of $X^\\top X$. (Left as an exercise for the reader.)  Since covariance matrix $X^\\top X$ is a symmetric and positive semidefinite matrix, its eigenvectors form an orthogonal basis with non-negative eigenvalues (obviously).\n",
    "- Eigenvectors are the *principal components* of $X$ (in order, if eigenvalues decreasing).\n",
    "- Corresponding eigenvalues are the variance of $X$ 'along' each component (also equal to the diagonals of $\\mathbf{S}_Y$) - or the 'variance explained' by each component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Principal Component Analysis\n",
    "\n",
    "- We have thus just derived (in abbreviated fashion) a ridiculously useful tool called PCA (Principle Component Analysis).\n",
    "  - It is a linear algebra method that tries to find uncorrelated Gaussians.  Uncorrelated sometimes coincides with statistically independent.\n",
    "  - *ICA (Independent Componenent Analysis)* derives independent features using probability and information theory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## Random Projections / RCA\n",
    "\n",
    "- This is a stupid, stupid algorithm that shouldn't work:\n",
    "  1. Pick $m$ random directions in the $n$-dimensional space, $m < n$.\n",
    "  2. Project the $n$-dimensional data onto them.\n",
    "  3. Is the projection good enough (e.g. low reprojection error)?\n",
    "     - Yes: You're done.\n",
    "     - No: Repeat step 1.\n",
    "- It does work - very quickly, and irritatingly well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Other References\n",
    "\n",
    "- Official R intro: https://cran.r-project.org/doc/manuals/R-intro.html\n",
    "- Evaluating the Design of the R Language (Morandat, Hill, Osvald, Vitek): http://r.cs.purdue.edu/pub/ecoop12.pdf\n",
    "- Impatient R, http://www.burns-stat.com/documents/tutorials/impatient-r/\n",
    "- R: The Good Parts, http://blog.datascienceretreat.com/post/69789735503/r-the-good-parts\n",
    "- ISLR (Intro. to Statistical Learning in R): http://www-bcf.usc.edu/~gareth/ISL/\n",
    "- ESL (Elements of Statistical Learning): http://statweb.stanford.edu/~tibs/ElemStatLearn/\n",
    "\n",
    "- For PCA: http://www.cs.princeton.edu/picasso/mats/PCA-Tutorial-Intuition_jp.pdf"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
